{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가를 위한 데이터셋을 불러와 1,000개만 선별\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "klue_mrc_test = load_dataset('klue', 'mrc', split='validation')\n",
    "klue_mrc_test = klue_mrc_test.train_test_split(test_size=1000, seed=42)['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩을 저장하고 검색하는 함수 구현\n",
    "import faiss\n",
    "\n",
    "def make_embedding_index(sentence_model, corpus):\n",
    "    embeddings = sentence_model.encode(corpus)\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "def find_embedding_top_k(query, sentence_model, index, k=5):\n",
    "    embedding = sentence_model.encode([query])\n",
    "    distances, indices = index.search(embedding, k)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 인코더를 활용한 순위 재정렬 함수 정의\n",
    "\n",
    "def make_question_context_pairs(question_idx, indices):\n",
    "    return [[klue_mrc_test['question'][question_idx], klue_mrc_test['context'][idx]] for idx in indices]\n",
    "\n",
    "def rerank_top_k(cross_model, question_idx, indices, k):\n",
    "    input_examples = make_question_context_pairs(question_idx, indices)\n",
    "    relevance_scores = cross_model.predict(input_examples)\n",
    "    reranked_indices = indices[np.argsort(relevance_scores)[::-1]]\n",
    "    return reranked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 지표(히트율)와 평가에 걸린 시간을 반환하는 함수 정의\n",
    "\n",
    "import time\n",
    "def evaluate_hit_rate(datasets, embedding_model, index, k=10):\n",
    "    start_time = time.time()\n",
    "    predictions = []\n",
    "    for question in datasets['question']:\n",
    "        predictions.append(find_embedding_top_k(question, embedding_model, index, k)[0])\n",
    "\n",
    "    total_prediction_count = len(predictions)\n",
    "    hit_count = 0\n",
    "    questions = datasets['question']\n",
    "    contexts = datasets['context']\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        for pred in prediction:\n",
    "            if contexts[pred] == questions[idx]:\n",
    "                hit_count += 1\n",
    "                break\n",
    "\n",
    "    end_time = time.time()\n",
    "    return hit_count / total_prediction_count, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 기본 임베딩 모델로 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "base_embedding_model = SentenceTransformer('shangrilar/klue-roberta-base-klue-sts')\n",
    "base_index = make_embedding_index(base_embedding_model, klue_mrc_test['context'])\n",
    "evaluate_hit_rate(klue_mrc_test, base_embedding_model, base_index, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 미세 조정한 임베딩 모델로 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_embedding_model = SentenceTransformer('shangrilar/klue-roberta-base-klue-sts-mrc')\n",
    "finetuned_index = make_embedding_index(finetuned_embedding_model, klue_mrc_test['context'])\n",
    "evaluate_hit_rate(klue_mrc_test, finetuned_embedding_model, finetuned_index, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 순위 재정렬을 포함한 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm.auto import auto\n",
    "\n",
    "def evaluate_hit_rate_with_rerank(datasets, embedding_model, cross_model, index, bi_k=30, cross_k=10):\n",
    "    start_time = time.time()\n",
    "    predictions = []\n",
    "    for question_idx, question in enumerate(tqdm(datasets['question'])):\n",
    "        indices = find_embedding_top_k(question, embedding_model, index, bi_k)[0]\n",
    "        predictions.append(rerank_top_k(cross_model, question_idx, indices, cross_k))\n",
    "    total_prediction_count = len(predictions)\n",
    "\n",
    "    hit_count = 0\n",
    "    questions = datasets['question']\n",
    "    contexts  = datasets['context']\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        for pred in prediction:\n",
    "            if contexts[pred] == questions[idx]:\n",
    "                hit_count += 1\n",
    "                break\n",
    "\n",
    "    end_time = time.time()\n",
    "    return hit_count / total_prediction_count, end_time - start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
